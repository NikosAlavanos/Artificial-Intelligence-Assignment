C:\Users\ecope\OneDrive\Desktop\PythonProject\.venv\Scripts\python.exe C:\Users\ecope\OneDrive\Desktop\PythonProject\Bayes.py 

2025-02-16 10:21:16.698341: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 10:21:17.330411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.

Complete data size: (25000, 10000) (25000,)
Training data size: (22500, 10000) (22500,)
Validation data size: (2500, 10000) (2500,)

Custom Bernoulli Naive Bayes Evaluation on Validation Set:
Accuracy: 0.8392
Precision: 0.8544
Recall: 0.8375
F1 Score: 0.8459

Classification Report (Validation):

              precision    recall  f1-score   support

    Negative       0.82      0.84      0.83      1183
    Positive       0.85      0.84      0.85      1317

    accuracy                           0.84      2500
   macro avg       0.84      0.84      0.84      2500
weighted avg       0.84      0.84      0.84      2500


--- Alpha search results ---
Alpha: 0.1, Accuracy: 0.8396, Precision: 0.8550, Recall: 0.8375, F1: 0.8462
Alpha: 0.5, Accuracy: 0.8400, Precision: 0.8552, Recall: 0.8383, F1: 0.8466
Alpha: 1.0, Accuracy: 0.8392, Precision: 0.8544, Recall: 0.8375, F1: 0.8459
Alpha: 2.0, Accuracy: 0.8408, Precision: 0.8576, Recall: 0.8368, F1: 0.8470
Alpha: 5.0, Accuracy: 0.8384, Precision: 0.8609, Recall: 0.8269, F1: 0.8435

Best Hyperparameter Result:
{'alpha': 2.0, 'accuracy': 0.8408, 'precision': 0.8575875486381322, 'recall': 0.8367501898253606, 'f1': 0.8470407378939278}

Scikit-learn BernoulliNB Evaluation on Validation Set (alpha=2.0):
Accuracy : 0.8408
Precision: 0.8576
Recall   : 0.8368
F1 Score : 0.8470

Classification Report (Validation):

              precision    recall  f1-score   support

    Negative       0.82      0.85      0.83      1183
    Positive       0.86      0.84      0.85      1317

    accuracy                           0.84      2500
   macro avg       0.84      0.84      0.84      2500
weighted avg       0.84      0.84      0.84      2500


--- Final model on Test Set (using best alpha) ---
Test metrics (Custom NB):
Accuracy : 0.8418
Precision: 0.8621
Recall   : 0.8138
F1 Score : 0.8373

Classification Report (Test) - Custom NB:

              precision    recall  f1-score   support

    Negative       0.82      0.87      0.85     12500
    Positive       0.86      0.81      0.84     12500

    accuracy                           0.84     25000
   macro avg       0.84      0.84      0.84     25000
weighted avg       0.84      0.84      0.84     25000


[BiLSTM] Training set shape: (22500, 200) 22500
[BiLSTM] Validation set shape: (2500, 200) 2500
[BiLSTM] Test set shape: (25000, 200) 25000

Loading pre-trained Word2Vec embeddings (GoogleNews-vectors-negative300)... This may take a while.

Using device: cpu

--- Training BiLSTM ---
Epoch 1/10 - Train Loss: 0.4331, Val Loss: 0.4086
Epoch 2/10 - Train Loss: 0.3414, Val Loss: 0.3485
Epoch 3/10 - Train Loss: 0.3079, Val Loss: 0.3974
Epoch 4/10 - Train Loss: 0.2804, Val Loss: 0.3482
Epoch 5/10 - Train Loss: 0.2526, Val Loss: 0.3371
Epoch 6/10 - Train Loss: 0.2286, Val Loss: 0.3903
Epoch 7/10 - Train Loss: 0.1960, Val Loss: 0.3608
Epoch 8/10 - Train Loss: 0.1667, Val Loss: 0.3903
Epoch 9/10 - Train Loss: 0.1386, Val Loss: 0.3989
Epoch 10/10 - Train Loss: 0.1060, Val Loss: 0.4505
Training complete. Best validation loss: 0.3370809091042869

[BiLSTM] Test Set Metrics:
Accuracy : 0.8558
Precision: 0.8286
Recall   : 0.8973
F1 Score : 0.8616

[BiLSTM] Classification Report (Test):
               precision    recall  f1-score   support

    Negative       0.89      0.81      0.85     12500
    Positive       0.83      0.90      0.86     12500

    accuracy                           0.86     25000
   macro avg       0.86      0.86      0.86     25000
weighted avg       0.86      0.86      0.86     25000


--- Final Comparison ---
Custom NB (best alpha=2.0) -> Test F1 = 0.8373
BiLSTM (test)                              -> F1      = 0.8616

Done! All parts integrated.


Process finished with exit code 0
